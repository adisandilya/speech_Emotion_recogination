# speech_Emotion_recogination
I have  made this project using LSTM which is a layer of RNN

DATASET
This is the link of the dataset used for this project https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess

Technologies Used: 
Python Pandas Scikit-learn Matplotlib Seaborn

RESULT
Accuracy: Varies depending on the model and features used, but generally ranges from 70% to 90%.
Common Models: Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs), and traditional machine learning models like Support Vector Machines (SVMs).
Feature Extraction: Mel-Frequency Cepstral Coefficients (MFCCs) are often used as features.
Challenges: Differentiating between emotions like sadness and neutral, or anger and disgust, can be difficult due to subtle differences in the speech signals.

Contributing Contributions are welcome! 
Please fork the repository and create a pull request for any changes or improvements. Ensure that your code follows the project's style guidelines and includes appropriate tests.

